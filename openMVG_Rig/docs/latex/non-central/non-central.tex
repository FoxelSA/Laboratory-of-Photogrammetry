% ==========================================================================================================
%   Document class and packages 
% ==========================================================================================================

\documentclass[a4paper, 10pt]{article}

\usepackage[latin1]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
%\usepackage{bbm}
\usepackage{lscape}
\usepackage{inputenc}
\usepackage{lmodern}
\usepackage{url}
\usepackage{float, graphicx}
\usepackage[sectionbib]{chapterbib}
\usepackage{hyperref}
\hypersetup{colorlinks=false, hidelinks}

% ==========================================================================================================
%   Commands 
% ==========================================================================================================

\renewcommand{\tilde}{\widetilde}
\renewcommand{\t}{\mathbf{t}}
\renewcommand{\d}{\mathbf{d}}
\renewcommand{\b}{\mathbf{b}}
\newcommand{\m}{\mathbf{m}}
\newcommand{\x}{\mathbf{x}}
\newcommand{\X}{\mathbf{X}}
\newcommand{\y}{\mathbf{y}}
\newcommand{\0}{\mathbf{0}}
\newcommand{\R}{\mathbb{R}}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\I}{\mathbb{I}}

% ==========================================================================================================
%   Author(s) and Title 
% ==========================================================================================================

\author{ St\'ephane Flotron, Pierre Moulon }
\title{\textbf{A new Global Pipeline solving the non-central camera SfM}}

% ==========================================================================================================
%   Document
% ==========================================================================================================

\begin{document}
   \maketitle
   
% ==========================================================================================================
%   Preambule
% ==========================================================================================================
   
   \section{ Preambule }
   
   \subsection{On the Plücker line representation}
   
   Let $L$ be a line of the 3D space $\R^3$ defined by the point $\x$ and $\y$. Let us now define $\d$ as 
   \begin{equation*}
       \d = \y-\x.
   \end{equation*}
   Then, The Cartesian representation of the line $L$ is 
   \begin{equation*}
       L : \x + \alpha \d, \ \alpha \in \R.
   \end{equation*}
   This representation of the line does not allow the use of homogeneous coordinates. Hence, a solution is to use Plücker
   line representation of $L$, $L : (\d,\m)$, where $\d$ and $\m$ are two vectors of $\R^3$ defined as :
   \begin{equation}
        \label{dandm}
       \d = \y-\x \mbox{ and } \m = (\x-\0) \wedge (\y-\0),
   \end{equation}
   where $\0$ is the origin of $\R^3$.
   
   \paragraph{}We are now interested us to intersection of lines represented in Plücker coordinate frame.
   Let $L_1 : (\d_1, \m_1)$ and $L_2 : (\d_2, \m_2)$ be two lines of $\R^3$ represented by Plücker
   line coordinates. $L_1$ intersect $L_2$ if and only if $L_1$ and $L_2$ are coplanar. In terms of Plücker 
   coordinates, this condition is the following :
   \begin{equation}
       \label{co-planarity condition}
       L_1 \cap L_2 \neq \emptyset \iff \d_1 \cdot \m_2 + \d_2 \cdot \m_1 = 0.
   \end{equation}

   \subsubsection*{Remark}
    In the case where $\x$ and $\y$ belongs to $\P^3$ (the projective space of dimension 3), the above definition of $\d$ and $\m$ does not hold anymore.
    Let us defined $p_{ij}$ as 
    \begin{equation*}
        p_{ij} = \left| 
             \begin{array}{cc}
                \x_i & y_i \\
                \x_j & y_j 
            \end{array}
        \right|.
    \end{equation*}
    Then $\d$ and $\m$ are defined as
    \begin{equation*}
           \d^T = (p_{01},\ p_{02},\ p_{03}) \mbox{ and } \m^T = (p_{23},\ p_{31},\ p_{12}). 
    \end{equation*}
    Taking $\x = (1, \x_1, \x_2, \x_3)$, $\y = (1, y_1, y_2, y_3)$ and using the above definition, 
    we recover $\d$ and $\m$ defined by relation \eqref{dandm}.
    
    \subsubsection{Rigid transformation of lines represented by Plücker coordinates}
    
    Let $\x$ and $\y$ be two vectors of $\R^3$ defining a line $L$. Here, we represent $L$ using Plücker line
    coordinates, $L : (m,d)$. We apply to $L$ the rigid transformation $f(\X) = R( \X-\t), \ \forall \X \in \R^3$, 
    where $R$ is a rotation matrix and $\t \in \R^3$. Denoting $L'=f(L)$ with Plücker coordinate $(\d', \m')$, 
    how are $\d'$ and $\m'$ related to $\m$ and $\d$ ? Using the definition \eqref{dandm} of $\d$ and $\m$, we have
    \begin{eqnarray*}
         \d' & = & f(\y) - f(\x) \\
             & = & R(\y-\t) -R(\x-\t) \\
             & = & R\y - R\x \\
             & = & R(\y-\x) \\
             & = & R\d.
    \end{eqnarray*}
    Similary, we have
    \begin{eqnarray*}
        \m' & = & f(\x) \wedge f(\y) \\
            & = & R(\x-\t) \wedge R(\y-\t) \\
            & = & R \x \wedge R\y - R\t \wedge R \y - R\x \wedge R \t \\
            & = & R( \x \wedge \y) - R\t \wedge R(\y-\x) \\
            & = & R( \x \wedge \y) - R( \t \wedge (\y -\x) \\
            & = & R \m - R ( \t \wedge \d ).
    \end{eqnarray*}
    Hence, for the rigid transformation $f$ defined by $f(\X) = R(\X-\t)$, we have
    \begin{equation}
       \label{plucker-transform}
        \d' = R\d \mbox{   and   } \m' = R\m - R ( \t \wedge \d ).
    \end{equation}
    The relation \eqref{plucker-transform} will be useful to derive the generalized epipolar constraint.
    
    \subsection{The generalized epipolar camera model}

    Let $L_1$ and $L_2$ be the rays related to the same 3D point seen by two cameras, respectively camera 1 and camera 2. We suppose that the Plücker line
    representation of $L_1$ and $L_2$ are known and denoted by
    \begin{equation*}
         L_1 : (\d_1, \m_1) \mbox{   and   } L_2 : (\d_2, \m_2 ).
    \end{equation*}
    We assume that $L_1$ is represented in camera 1 coordinate frame and that $L_2$ is represented in camera 2 coordinate frame.
    Without loss of generality, we can assume that camera 1 has pose $(\I_3 | \0)$ and that camera 2 has pose $(R, \t)$, where $R$ the orientation of
    the second camera with respect to the first and $\t$ the translation of second camera in camera 1 coordinate frame. 
    Denoting by $\X$ a point in camera one coordinate frame, it could be expressed in camera 2 coordinate frame by
    $$ \x_{cam}^2 = R\x_{cam}^1 + \t.$$
    Therefore, $\x_2^{cam}$ expressed in camera one coordinate frame is given by the following relation: 
    $
        \x_{cam}^1 = R^T( \x_{cam}^2 - \t). 
    $
    Hence, $L_2$ in camera one coordinate frame is given by :
    \begin{equation*}
        L^2 : (R^T \d_2, R^T \m_2 - R^T (\t \wedge \d_2).
    \end{equation*}
    Since $L_1$ and $L_2$ are seeing the same 3D point $\X$, the lines must intersect. From condition \eqref{co-planarity condition}, we have
    \begin{equation*}
        \d_1^T R^T \m_2 - \d_1^T R^T (\t \wedge \d_2 ) + \m_1^T R^T \d_2 = 0,  
    \end{equation*}
    which is equivalent to 
    \begin{equation}
        \label{ray intersection}
        \m_2^T R \d_1 + \d_2^T [\t]_{\times} R \d_1 + \d_2^T R \m_1 = 0.
    \end{equation}
    Writing equation \eqref{ray intersection} into a matrix product, we obtain the following expression
    \begin{equation}
        \label{generalized epipolar}
        (\d_2^T\ \m_2^T ) \left[ 
          \begin{array}{cc}
              [\t]_{\times} R & R \\
              R & \0 
          \end{array}
           \right] 
           \left( 
               \begin{array}{c}
                   \d_1 \\
                   \m_1
               \end{array}
           \right)
           = 0
    \end{equation}
    which the generalized epipolar condition. Let us remark that if we consider central camera, the momentums $\m_1$ and $\m_2$
    are equal to $\0$ because the rays passes through the origin. Then relation \eqref{generalized epipolar} reduces to
    $$ \d_2^T [\t]_{\times} R \d_1 = 0$$
    which is nothing else than the classical epipolar condition. Therefore \eqref{generalized epipolar} is
    a generalization of the epipolar condition.
    
% ==========================================================================================================
%   Relative pose estimation
% ==========================================================================================================
    
   \section{Relative Rotation Estimation}
   
   In this section, we assume that we know 2D-2D correspondences between two poses. The keypoint is to estimate the relative
   rotation $R$ and the relative translation $\t$ between two poses. 
   
   \subsection{State of the art}
   
   This field is quite new, but it more and more explorated. Although, all the methods share the same approach : they try
   to solve equation \eqref{generalized epipolar}, which has 6 degrees of freedom. 
   The most natural approach to solve \eqref{generalized epipolar} is to use the a singular-value decomposition to find $R$ and $\t$, as
   done in \cite{17-points-4587545}. However, this approach generally fails because the equation \eqref{generalized epipolar}
   has a family of solutions, and hence the solution is not unique anymore (see \cite{17-points-4587545} for a more detailed 
   explanation). This is major difference between non central cameras and central cameras, because in the central camera case, 
   the solution is unique up to a scale factor (see \cite{Hartley:2003:MVG:861369}). \paragraph{}
   
   Because the standard linear algorithm generally fails, there is some others methods that have developped during
   the last years. For example, \cite{Stewenius05solutionsto} uses exactly 6 correspondances in order to solve \eqref{generalized epipolar}.
   However, this methods is quite difficult to implement. Indeed, it uses Gröbner basis and the 6 points leads to 64 solutions
   that have to be discarded using different solution. In a practical way, the 6 point method takes munch more time 
   that the standard linear algorithm, but is more resilient to noise and outliers.

   Recently, Kneip and al. presented a new method based on generalized eigenvalue (GE) decomposition \cite{ge-kneip}. The key idea of 
   this method is to split \eqref{generalized epipolar} in a rotation estimation using rank minimization approach, 
   followed by a translation estimation. This methods has the nice property to be more noise and outiler resilient than
   the 6-point method and the 17-point method. Moreover, GE method is faster than 6-point or 17-point method methods. 
   However, this method need a good initial estimate of the relative rotation to produce an accurate estimation. And the minimization
   strategy could be improved using an other method than gradient descent. In pratice, in a RANSAC framework, 
   the estimated model are of a satisfying quality to be used in a global method. However, the relative pose estimation could
   be munch improved in order to gain accuracy for the whole global pipeline that we will present later.
   
   \subsection{Relative pose estimation}
   
   Actually, in our software, we use the OpenGV library \cite{opengv, opengv-online} in order to evaluate the relative pose between two non-central cameras.
   OpenGV library is a C++ free software containing various methods to estimate relative and absolute poses for both central and non-central 
   cameras. In our case, we only use the part related to non-central cameras, which contains an implementation of the 
   6-points methods solver \cite{Stewenius05solutionsto}, the 17-points solver \cite{17-points-4587545} and the generalized
   eigenvalue solver \cite{ge-kneip}. In our sofware, we use the generalized eigenvalue software.
  
% ==========================================================================================================
%   Relative translation estimation
% ==========================================================================================================
    
   \section{Relative translation Estimation}
   
   During this section, we assume that the rotation $R_i$ of each pose $i$ is known. The aim of this section is to develop
   a numerical scheme in order to estimation the relative translations $\t_{ij}$ between two poses. Once the are known, 
   the relative translations could be merged using the approach of \cite{moulon-tel-00996935} in order to retrieve the global translations.
   
   \subsection{Parametric model (reduced trifocal tensor)} 
   We assume here that the tracks between the poses are know, i.e that correspondences between the sub cameras
   of the camera rigs are known. The tracks are assumed to be of length at least 3, so that the corresponding 3D point is
   seem from at least three poses. The method presented hereafter is based on the one developed by Pierre Moulon
   (see \cite{moulon-tel-00996935} chapter 6, section 6.2.3, p.129 for the original method). Following \cite{moulon-tel-00996935}, 
   we define the interpose similarity measure as the re-projection error defined by 
    \begin{equation}
        \label{similarity}
        \begin{aligned}
        & \rho(\t_i, \X_j) && = \left \| \left (
                              \x_j^{c,i}(1) - \frac{(R_c R_i \X_j + R_c \t_i + \t_c)^1}{(R_c R_i \X_j + R_c \t_i + \t_c)^3}, \right. \right. \\
                           &&& \qquad \qquad \qquad  \left. \left. \x_j^{c,i}(2) - \frac{(R_c R_i \X_j + R_c \t_i + \t_c)^2}{(R_c R_i \X_j + R_c \t_i + \t_c)^3}
                          \right) \right\|_\infty
        \end{aligned}
    \end{equation}
    where
    \begin{itemize}
        \item[$\x_j^{c,i}$] is the pixel of sub-camera $c$ of pose $i$ corresponding to the 3D point $\X_j$ 
        \item[$\X_j$] is a 3D point,
        \item[$R_c$] is the relative orientation of the sub-camera $c$ in the camera rig referential frame,
        \item[$R_i$] is the orientation of pose $i$,
        \item[$\t_i$] is the translation of pose $i$,
        \item[$\t_c$] is the translation of sub-camera $c$ in the camera rig referential frame.
    \end{itemize}
   
   Le be $(I,J,K)$ a triplet of poses such that the composition of the relative rotation is the 
   identity matrix, i.e.
   $$ R_{IJ} R_{JK} R_{KI} = I_3.$$ 
   where $R_{ij}$ is the relative orientation of rig $j$ in the pose $i$. 
   The problem we want to solve in order to estimate the relative translation
   $\t_1 = \mathbf{0}, \t_2= \t_{IJ}, \t_3 = \t_{IK}$ between the poses $I, J$ and $K$ is 
   \begin{equation}
       \label{parametric model}
       \begin{aligned}
           \underset{\{\t_i\}_i, \{\X_j\}_j}{\mbox{minimize}}  && \quad  & \gamma &&& \\
           &&&&&\\
           \mbox{such that} && \ & \rho(\t_i, \X_j) \leq \gamma && \forall i, j \in \{1,2,3,4\} \\
            & && (R_c R_i \X_j + R_c \t_i + \t_c)^3 \geq 1 & \ & \forall i,j \\
            &&& \t_1 = (0,0,0) &&
       \end{aligned}
   \end{equation}
   Only 4 3D-points are needed to estimate the relative translations between the three poses. 
   The model would be estimated using AC-RANSAC with an upper bound threshold of $\gamma=2.0$ pixels. For more information
   about the mathematical basis of the model, we refer us to \cite{moulon-tel-00996935}.
   
   \subsubsection*{Note}
   Denoting by $R^k$ the $k$-th row of the matrix $R$, The constraint $\rho(\t_i, \X_j) \leq \gamma$ is equivalent to 
   \begin{equation*}
     \left\{
         \begin{aligned}
            & \X_j\left[ (R_cR_i)^k + (\gamma-\x_j^{c,i}(k)) (R_cR_i)^3 \right] + \left[R_c^3(\gamma-\x_j^{c,i}(k))+R_c^k\right]\t_i  \\
            & \qquad \qquad + [\t_c^k + (\gamma-\x_j^{c,i}(k))\t_c^3] \geq 0 \\
            & \X_j\left[ (R_cR_i)^k - (\gamma + \x_j^{c,i}(k)) (R_cR_i)^3 \right] + \left[-R_c^3(\gamma+\x_j^{c,i}(k))+R_c^k\right]\t_i  \\
            & \qquad \qquad + [\t_c^k - (\gamma+\x_j^{c,i}(k))\t_c^3] \leq 0 \\
         \end{aligned}
       \right\}, \\ \forall k \in {1,2}.
   \end{equation*}
   Because $R_c$ et $\t_c$ are known from calibration, the previous problem is linear in $\X_j$ and $\t_i$.
   
   \subsection{3D points distance minimization}
   The previous formulation seems quite fine, but from the representation of the re-projection error, we
   are still in a central camera case with three cameras, even if we consider the sub-poses in the formulation
   of model \eqref{parametric model}.
   
   \paragraph{} In order to avoid this problem, we present now a model in which we are 
   in a global referential frame, which seems more suitable for the representation of the scene with non 
   central cameras. Let $\X$ be a 3D point seen from camera $c$ with sub-pose ($R_c, C_c$) in a camera
   rig of pose $(R_r, C_r)$. Moreover, let us denote the corresponding bearing vector as $\b$. Then the relation
   between $\b$ and $\X$ is
   \begin{equation*}
      \alpha \b = R_c R_r \X + R_c \t_r + \t_c 
   \end{equation*}
   where $\alpha$ is the depth of the point $\X$ in the camera $c$ referential frame, $\t_c = -R_c C_c$ and $\t_r = -R_r C_r$. 
   Inverting the previous relation leads to the following equation 
   \begin{equation*}
       \X = \alpha R_r^T R_c^T  \b + R_r^T C_c + C_r.
   \end{equation*}
   Let $\X_l$, $l \in \mathbb{N}$ a 3D points issued from pose $i$ and sub-camera $k$. Then 
   \begin{equation*}
      \X_l = \alpha_l^i R_i^T R_k^T  \b_l + R_i^T C_{k} + C_i
   \end{equation*}
   and if $\X_l$ is seen from two poses $i$ and $j$, we have
   \begin{eqnarray*}
     \X_l & = & \X_{l, i} = \alpha_l^i R_i^T R_{k,i}^T  \b_{l, i} + R_i^T C_{k,i} + C_i \\
          & = & \X_{l, j} = \alpha_l^j R_j^T R_{k,j}^T  \b_{l, j} + R_j^T C_{k,j} + C_j.
   \end{eqnarray*}
   However, in practice, the bearing vectors $\b_{l,i}$ and $\b_{l,j}$ are noisy so that the above equality is never 
   fulfilled. Nevertheless, we can ensure that the distance between $\X_{l,i}$ and $\X_{l,j}$ is 
   less than a given threshold $\sigma$. In fact we would ensure that 
   \begin{equation*}
       \| \X_{l, i} -\X_{l, j} \|_{\infty} \leq \sigma.
   \end{equation*}
   Le be $(I,J,K)$ a triplet of poses such that the composition of the relative rotation is the 
   identity matrix, i.e.
   $$ R_{IJ} R_{JK} R_{KI} = I_3.$$ 
   where $R_{ij}$ is the relative orientation of rig $j$ in the pose $i$.
   We could now present the scheme based on distance minimization. We assume that for each of the three poses we know the bearings vectors 
   corresponding to a 3D points $\X_l$, $l=0,\dots,3$. In practice, this means that 4 tracks of length greater or equal 3 are known, and that the tracks
   are shared by the three poses $I, J$ and $K$. Knowing that, 
   we are looking for depths $\alpha_{l,i}$ and poses center that minimize the following problem:
   \begin{equation*}
       \begin{aligned}
          \underset{\{C_i\}_i, \{\alpha_l^i\}_{l,i}}{ \mbox{minimize}}  && \quad  & \sigma &&& \\
           &&&&&\\
           \mbox{such that} && \ & \| \X_{l,i} - \X_{l,j}\|_{\infty} \leq \sigma && \\
           &&& \forall l \in \{0,1,2,3\}, \forall i \neq j \in \{I,J,K\} \\
       \end{aligned}
   \end{equation*}
   However, in pratice, we need the relative translations, so we consider the following equivalent problem:
   \begin{equation}
       \label{distance translation model}
       \begin{aligned}
          \underset{\{\t_i\}_i, \{\alpha_l^i\}_{l,i}}{ \mbox{minimize}}  && \quad  & \sigma &&& \\
           &&&&&\\
           \mbox{such that} && \ & \| \overline {\X}_{l,i} - \overline {\X}_{l,j}\|_{\infty} \leq \sigma && \\
           &&& \forall l \in \{0,1,2,3\}, \forall i \neq j \in \{I,J,K\} \\
       \end{aligned}
   \end{equation}
   where 
   \begin{equation*}
       \overline{\X}_{l, i} = \alpha_l^i R_i^T R_{k,i}^T  \b_{l, i} + R_i^T C_{k,i} -R_i^T \t_i.
   \end{equation*}
   The model would be estimated using AC-RANSAC with an upper bound threshold $\sigma=0.01$ meters, because 
   we made the implicit assumption that the centers $C_k$ of the cameras of the rig structure are in meters.
   
   \subsubsection*{Remark}
   Denoting by $1_3$ the vector $(1,1,1)^T$, the equation $ \| \overline {\X}_{l,i} - \overline {\X}_{l,j}\|_{\infty} \leq \sigma $ could easily 
   be rewritten as 
   \begin{equation}
     \label{expanded distance}
     \begin{aligned}
       & -\sigma 1_3 -R_i^T C_{k,i} + R_j^T C_{k,j} & \leq & 
          \ \alpha_i^l R_i^T R_{k,i}^T \b_{l,i} - \alpha_j^l R_j^T R_{k,j}^T \b_{l,j}
             -R_i^T \t_i + R_j^T \t_j \\
       && \leq & \sigma 1_3 -R_i^T C_{k,i} + R_j^T C_{k,j}.
     \end{aligned}
   \end{equation}
   The equation \eqref{expanded distance} could be split into two inequalities which are easy to implement in a linear programming solver such 
   as OSI-CLP \cite{clp, osi}.

% ==========================================================================================================
%   Global pipeline
% ==========================================================================================================

   \section{A global method solving the non-central SfM}
   
   Now, we describe the algorithm we develop in order to solve the non-central structure from motion (SfM). 
   The only input needed is the sub-pose $(R, C)$ of each channels of the camera rig, as the calibration 
   information of each sensors (camera matrix, optical distorsion, etc.). Moreover, we assume that pairwise
   matches between images are given as an input to software. We mean that all pixels correspondances between 
   images pairs are known, and that they are noise-free (i.e. they are filetered using a fundamental
   or essential filter). \paragraph{}
   
   The algorithm we develop is based on the global method used in \cite{moulon-tel-00996935}. The method
   is well documented in \cite{moulon-tel-00996935}, so we will only describe the main steps of computation.
   The method we developped consists in 5 main steps :
   \begin{enumerate}
       \item  Evaluate the relative rotations between poses using the openGV library.
       \item  Merge all the relative rotations in order to have the global rotations.
       \item  Given the global rotation of point 2, evaluate the relative translations per group of 3
              connected poses using scheme \eqref{distance translation model}.
       \item  Merge all the estimated relative translations in order to have the global rotations.
       \item  Do bundle adjustement in order to refine the computed scene and structure.
   \end{enumerate}
   We refer to \cite{moulon-tel-00996935} for a detailled description of the fusion of the relative rotation 
   and translations.

   
% ==========================================================================================================
%   Conclusions
% ==========================================================================================================
   
   \section{Conclusions}
   
% ================================================================
%  Bibliography
% ================================================================

  \bibliography{biblio}
  \bibliographystyle{acm}
%  \bibliographystyle{plain}
   
\end{document}
